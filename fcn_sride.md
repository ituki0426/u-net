---
marp: true
---
<!--
headingDivider: 1
-->

# Fully Convolutional Networks for Semantic Segmentation

今回は、CNNをピクセル単位の学習・推論が必要なセグメンテーションタスクに応用する手法を提案したFully Convolutional Networks for Semantic Segmentationという論文について説明します。

---


Fully Convolutional Networksとは...

全結合層を持たず、線形層が全て畳み込み層だけで構成されているCNN。そのため、Deconvolution（転置畳み込み）を用いることで任意のサイズの入力を受け取り、対応するサイズの出力を効率的に推論・学習することが可能なネットワーク

このような，全結合層を無くして「出力層付近(ヘッド)も，全て畳み込み層で済ませるCNN」を，全結合が終盤に備わっているCNNと区別する意味で，「Fully Convolutional なニューラルネットワーク」(あるいは「Fully convolutional な CNN = FCN」)と呼ぶ．

---


## Deconvolution(転置畳み込み) = 畳み込みの逆操作

![](./img/image%20copy%208.png)

入力データを高解像度にすることが出来る。

---

### FCNでないモデル(ex.VGG16)


![](./img/image%20copy%207.png)

---

本論文ではFCNをセグメンテーションに応用する手法を提案します。

CNNは画像分類など、画像全体に対する推論（＝粗い推論）は2014年当時成功していた。


そのため次のステップとして、あらゆるピクセルに対して予測を行う(ex.セマンティックセグメンテーション)研究が進められていた。

本論文での提案手法登場以前も、ConvNet をセマンティックセグメンテーションに使用してきたが、精度・推論時間などの欠点があり、それを解決したのが本論文の提案手法である。


画像上の **各画素（または粗いグリッド）** を中心に小さなパッチを切り出し，そのパッチを 分類器として訓練した CNN に入力する。」


画素数だけCNNの推論を回す必要がある。さらに、重複パッチが多いため計算が冗長で、推論に時間がかかる。


---

## 最初に提案されたアーキテクチャ = Encoder部分とDecoder部分からなるFCNアーキテクチャ

![](./img/image%20copy%209.png)

---

Encocer部分：従来のCNNに似ており、畳み込み層とプーリング層によって構成され、空間的な次元を段階的に縮小しつつ、特徴チャネルの数を増加させます。

Decoder部分：この部分では、転置畳み込み(UpSampling)を用いて特徴マップを元の入力解像度までアップサンプリングします。最終出力層にsoftmaxを適用し、各クラスの確率を推定している。

また、セグメンテーションタスクにおけるFCNの損失関数はピクセルごとのクロスエントロピー損失（pixel-wise cross-entropy loss）の総和になる。

---

入力画像 $\boldsymbol{x} \in \mathbb{R}^{H \times W \times C}$ に対して、モデル出力を

$$
\hat{\boldsymbol{y}}_{ij} = \mathrm{softmax}(\boldsymbol{z}_{ij}) \in \mathbb{R}^K
$$

とします。

ここで：

- $\boldsymbol{z}_{ij}$ は画素 $(i, j)$ における各クラスのスコア（logits）
- $K$ はクラス数
- $\hat{\boldsymbol{y}}_{ij,k}$ は画素 $(i, j)$ がクラス $k$ である確率


正解ラベル $\boldsymbol{y}_{ij} \in \{0, 1\}^K$（ワンホットベクトル）に対して、損失関数 $\mathcal{L}$ は次のように定義されます：

$$
\mathcal{L} = -\sum_{i=1}^H \sum_{j=1}^W \sum_{k=1}^K y_{ij,k} \log \hat{y}_{ij,k}
$$
---

## 学習済み画像分類モデルへの適用

画像分類タスクで学習されたAlexNet、VGG net、および GoogLeNetのネットワークに変更を加えることでFCNにし、それらの学習済み表現をファインチューニングによってセグメンテーションタスクに転用することができる。

AlexNet、VGG net、および GoogLeNetは、一見すると固定サイズの入力しか受け取らず、空間的情報を持たない（＝座標を失った）出力だけを生成する。

---

これらのネットワークにおける全結合層は出力次元が固定で、入力画像上の座標を捨ててしまうから。

しかし、この全結合層は「入力領域全体を覆うカーネル (kernel; 畳み込み核) を用いた畳み込み」と見なすこともできる。

こう捉え直すと、ネットワーク全体は 全畳み込みネットワーク (Fully Convolutional Network; FCN) となり、softmaxなどの最終出力層を取り除き、Deconvolution層を追加することで、任意の大きさの入力を受け取って 分類マップ (classification map) を出力できるようになります。

---

ex）VGG16をFCNに転用する様子

![](./img/image%20copy%2012.png)

---

たとえば  **AlexNet** は、227 × 227 ピクセルの画像に対する分類スコアを生成するのに（一般的な GPU で）**1.2 ms** かかりますが、**完全畳み込み版（FCN 化）** では、500 × 500 ピクセルの画像から **10 × 10** の出力グリッドを得るのに **22 ms** しか掛かりません。これは **素朴なパッチ単位の手法より 5 倍以上** 高速。


また、どのモデルをFCN化するかによって精度が異なる。

下記のテーブルはPASCAL VOC 2011というアノテーション付き画像のデータセット(train  2223 枚  オブジェクト 5034個)に各モデルをFCN化してファインチューニングした結果です。


![](./img/image%20copy%2013.png)


---

## スキップ接続を用いたアーキテクチャ(これがU-Netにつながった)

ストライド付き畳み込み（strided convolution）やプーリングで解像度を下げると，ピクセル単位の細かな位置情報は捨てられる。

セグメンテーションにおいて、位置情報が失われてしまうと精度は出ない...(上記に示したPASCAL VOC 2011データセットの学習結果を見れば明らか)

そこで、スキップ接続というものを上記のFCNアーキテクチャに追加することが論文で提案された。

スキップ接続により、上層のまだ位置情報を次元的に圧縮仕切っていない情報を、下層のアップサンプリングの際に足し合わせることで精度の良いセグメンテーションを実現する。

---

![Image](./img/image%20copy%2010.png)

上記の様に、Pooling層の出力をDeconvolutionの出力と足し合わせることでスキップ接続を構成する。

---

本論文では、FCN化したVGG16にスキップ接続を追加して精度を検証した。何個のプーリング層からデータを持ってくるかで、下記の様に分けられる。

![](./img/image%20copy%2014.png)

---

下記のテーブルは、上記でも使用したPASCAL VOC 2011を各FCNアーキテクチャに適用したときの結果を示します。

![](./img/image%20copy%2015.png)

直観的にも分かるように、使用プーリング層の数が多い、すなわち、より多くのスキップ接続を加える方が、精度はよくなる。

---

## FCNに残された課題


それまであった、CNNをセグメンテーションタスクに適用する際の計算冗長性、CNNを画素数だけ適用することによる遅い推論時間。


FCNはこれらを解決することはできた。


しかし、スキップ接続を導入しても精度があまり良くなかった。
